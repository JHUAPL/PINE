:py:mod:`pine.backend.pineiaa.bratiaa`
======================================

.. py:module:: pine.backend.pineiaa.bratiaa


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   agree/index.rst
   agree_cli/index.rst
   evaluation/index.rst
   iaa_service/index.rst
   utils/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   pine.backend.pineiaa.bratiaa.F1Agreement
   pine.backend.pineiaa.bratiaa.Document



Functions
~~~~~~~~~

.. autoapisummary::

   pine.backend.pineiaa.bratiaa.compute_f1_agreement
   pine.backend.pineiaa.bratiaa.iaa_report
   pine.backend.pineiaa.bratiaa.input_generator
   pine.backend.pineiaa.bratiaa.exact_match_instance_evaluation
   pine.backend.pineiaa.bratiaa.exact_match_token_evaluation
   pine.backend.pineiaa.bratiaa.tokenize



Attributes
~~~~~~~~~~

.. autoapisummary::

   pine.backend.pineiaa.bratiaa.AnnFile
   pine.backend.pineiaa.bratiaa.Annotation


.. py:function:: compute_f1_agreement(annotators, documents, labels, token_func=None, eval_func=None)


.. py:function:: iaa_report(f1_agreement, precision=3)


.. py:data:: AnnFile
   

   

.. py:class:: F1Agreement(annotators, documents, labels, eval_func=exact_match_instance_evaluation, token_func=None)

   .. py:method:: annotators(self)
      :property:


   .. py:method:: documents(self)
      :property:


   .. py:method:: labels(self)
      :property:


   .. py:method:: _compute_tp_fp_fn(self, documents)


   .. py:method:: _increment_counts(self, annotations, pair, doc, kind)


   .. py:method:: mean_sd_per_label(self)

      Mean and standard deviation of all annotator combinations' F1 scores by label.


   .. py:method:: mean_sd_per_document(self)

      Mean and standard deviation of all annotator combinations' F1 scores per document.


   .. py:method:: mean_sd_total(self)

      Mean and standard deviation of all annotator cominations' F1 scores.


   .. py:method:: mean_sd_per_label_one_vs_rest(self, annotator)

      Mean and standard deviation of all annotator combinations' F1 scores involving given annotator per label.


   .. py:method:: mean_sd_total_one_vs_rest(self, annotator)

      Mean and standard deviation of all annotator combinations' F1 scores involving given annotator.


   .. py:method:: _pairs_involving(self, annotator)


   .. py:method:: _mean_sd(f1_pairs)
      :staticmethod:

      Mean and standard deviation along first axis.


   .. py:method:: print_table(row_label_header, row_labels, avg, stddev, precision=3)
      :staticmethod:


   .. py:method:: compute_total_f1_matrix(self)

      Returns (n x n) matrix, where n is the number of annotators, containing
      pair-wise total F1 scores between all annotators.

      By definition, the matrix is symmetric and F1 = 1 on the main diagonal.


   .. py:method:: draw_heatmap(self, out_path)

      Draws heatmap based on square matrix of F1 scores.



.. py:class:: Document(txt, doc_id)

   .. py:attribute:: __slots__
      :annotation: = ['ann_files', 'txt', 'doc_id']

      


.. py:function:: input_generator(json_list)


.. py:function:: exact_match_instance_evaluation(ann_list_1, ann_list2, tokens=None)


.. py:function:: exact_match_token_evaluation(ann_list_1, ann_list_2, tokens=None)

   Annotations are split into token-sized bits before true positives, false positives and false negatives are computed.

   Sub-token annotations are expanded to full tokens. Long annotations will influence the results more than short
   annotations. Boundary errors for adjacent annotations with the same label are ignored!


.. py:data:: Annotation
   

   

.. py:function:: tokenize(text)


